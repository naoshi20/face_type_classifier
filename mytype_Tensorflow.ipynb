{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from faces_128_utils import *\n",
    "#from faces_test_utils import *\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 1 0 1 0 1 0 0 1 1 2 1 1 1 1 1 2 2 1 0 1 2 1 1 1 0 1 1 1 1 0 2 0 2 1\n",
      "  0 1 0 2 1 1 1 1 1 1 1 2 1 2 2 0 1 1 1 2 1 1 1 1 1 1 1 1 0 2 0 1 1 1 1 1\n",
      "  1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1\n",
      "  1 2 1 1 1 1 2 2 0 1 1 1 1 2 1 1 1 1 0 1 1 1 1 1 2 2 2 2 1 2 1 1 1 1 1 1\n",
      "  2 1 1 2 1 1 2 1 2 0 0 2 1 0 2 1 0 2 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1\n",
      "  2 0 2 1 1 1 0 1 1 1 1 2 2 1 1 1 1 1 0 1 1 1 1 1 1 2 0 1 1 1 0 0 1 1 0 2\n",
      "  1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 2 1 1 1 2 1 0 2 1 1 1 1 1 0 1 2\n",
      "  1 1 0 1 1 0 1 2 1 1 1 2 2 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 0 1 2 1 2 1 0 1\n",
      "  2 1 1 1 1 1 2 1 0 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 0 1 1 2 0 2 1 1 1 1 1 1\n",
      "  2 1 1 1 1 0 2 1 1 1 1 1 0 0 1 0 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1\n",
      "  1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 2 1 1 2 1 2 1 1 1 1 0 0 0 2 2 2\n",
      "  1 2 1 1 1 1 0 1 1 1 1 1 2 1 2 2 1 2 2 2 1 1 1 1 1 1 2 1 1 1 0 0 1 1 1 0\n",
      "  2 1 1 1 2 2 2 2 1 2 1 1 1 0 2 1 0 1 1 1 1 2 0 2 1 1 2 1 0 2 1 0 1 1 1 0\n",
      "  0 0 2]]\n",
      "This image represents 0.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"plt.imshow(X_train_orig[0])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, 0])))\"\"\"\n",
    "\n",
    "im1 = X_train_orig[0]\n",
    "im2 = Image.new(\"RGB\", (128,128))\n",
    "for y in range(128):\n",
    "    for x in range(128):\n",
    "        r = im1[x][y][0]\n",
    "        g = im1[x][y][1]\n",
    "        b = im1[x][y][2]\n",
    "        im2.putpixel((y,x),(r,g,b))\n",
    "im2.show()\n",
    "label = Y_train_orig[0][0]\n",
    "print(Y_train_orig)\n",
    "print(\"This image represents \" + str(label) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 471\n",
      "number of test examples = 203\n",
      "X_train shape: (471, 128, 128, 3)\n",
      "Y_train shape: (471, 3)\n",
      "X_test shape: (203, 128, 128, 3)\n",
      "Y_test shape: (203, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 3).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 3).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_y])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "        \n",
    "    W1 = tf.get_variable('W1',[4, 4, 3, 8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable('W2',[2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \"\"\"\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding='SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1, 4, 4, 1], strides = [1, 4, 4, 1], padding='SAME')\n",
    "    # FLATTEN\n",
    "    P = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P, 3, activation_fn=None)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.005, num_epochs=150, minibatch_size=64, print_cost=True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    step = 0\n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            step += 1\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \"\"\"\n",
    "        print(parameters['W1'].eval())\n",
    "        print(parameters['W2'].eval())\n",
    "        \"\"\"\n",
    "        # save\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, 'save/onepiece_tfmodel', global_step = step, write_meta_graph = False)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.073715\n",
      "Cost after epoch 5: 0.984586\n",
      "Cost after epoch 10: 0.966522\n",
      "Cost after epoch 15: 0.920170\n",
      "Cost after epoch 20: 0.865326\n",
      "Cost after epoch 25: 0.815469\n",
      "Cost after epoch 30: 0.769394\n",
      "Cost after epoch 35: 0.740408\n",
      "Cost after epoch 40: 0.691806\n",
      "Cost after epoch 45: 0.717139\n",
      "Cost after epoch 50: 0.540761\n",
      "Cost after epoch 55: 0.542965\n",
      "Cost after epoch 60: 0.420274\n",
      "Cost after epoch 65: 0.374535\n",
      "Cost after epoch 70: 0.315794\n",
      "Cost after epoch 75: 0.323979\n",
      "Cost after epoch 80: 0.251856\n",
      "Cost after epoch 85: 0.198103\n",
      "Cost after epoch 90: 0.165787\n",
      "Cost after epoch 95: 0.155995\n",
      "Cost after epoch 100: 0.139984\n",
      "Cost after epoch 105: 0.112611\n",
      "Cost after epoch 110: 0.084436\n",
      "Cost after epoch 115: 0.093433\n",
      "Cost after epoch 120: 0.054826\n",
      "Cost after epoch 125: 0.041189\n",
      "Cost after epoch 130: 0.045814\n",
      "Cost after epoch 135: 0.059252\n",
      "Cost after epoch 140: 0.028561\n",
      "Cost after epoch 145: 0.024213\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VfX9+PHXOzd7kJABARJIiIGw\nZQuCoqKCi1oXzrpr/VqtWlut/tRqd6utdWtVtHVvVJQqggNZYW8IO6wkjEyy378/zkl6iQkE5Obe\nJO/n43Ef3HvO5577PifkvvMZ5/MRVcUYY4wBCPJ3AMYYYwKHJQVjjDH1LCkYY4ypZ0nBGGNMPUsK\nxhhj6llSMMYYU8+SgmmTRORTEfmJv+MwprWxpGCOKRHZLCLj/R2Hqk5U1Zf9HQeAiMwSketb4HPC\nRORFESkSkV0icsdhyt/ulity3xfmtS9NRGaKSJmIrPH+mYrI1SJSIyIlXo9xPjw104IsKZhWR0SC\n/R1DnUCKBXgQyAR6AKcAvxKRCY0VFJEzgbuB09zyPYHfehV5HVgMJAD3Au+ISJLX/jmqGu31mHWM\nz8X4iSUF02JE5BwRWSIi+0XkOxEZ6LXvbhHZICLFIrJKRM732ne1iMwWkb+LyB7gQXfbtyLyNxHZ\nJyKbRGSi13vq/zpvRtl0Efna/ewvRORJEflPE+cwTkRyReTXIrILeElEOorIxyKS7x7/YxFJccv/\nHhgLPOH+Rf2Euz1LRD4Xkb0islZELj4Gl/gnwMOquk9VVwPPA1cfouwLqrpSVfcBD9eVFZFewBDg\nAVU9oKrvAsuBC45BjCbAWVIwLUJEBgMvAj/F+evzWWCqV5PFBpwvz1icv1j/IyJdvA4xEtgIdAZ+\n77VtLZAI/AV4QUSkiRAOVfY1YL4b14PAlYc5nWQgHucv7Btxfo9ecl93Bw4ATwCo6r3AN8At7l/U\nt4hIFPC5+7mdgMnAUyLSt7EPE5Gn3ETa2GOZW6Yj0AVY6vXWpUC/Js6hXyNlO4tIgrtvo6oWH+JY\ng0WkQETWicj/C7Aak/kBLCmYlnIj8KyqzlPVGre9vwI4AUBV31bVHapaq6pvAuuBEV7v36Gqj6tq\ntaoecLdtUdXnVbUGeBnnS7FzE5/faFkR6Q4MB+5X1UpV/RaYephzqcX5K7rC/Ut6j6q+q6pl7hfp\n74GTD/H+c4DNqvqSez6LgXeBixorrKo3q2pcE4+62la0+2+h11sLgZgmYohupCxu+Yb7Gh7ra6A/\nTkK7ALgUuOsQ52taEUsKpqX0AO70/isXSAW6AojIVV5NS/txvnQSvd6/rZFj7qp7oqpl7tPoRsod\nqmxXYK/XtqY+y1u+qpbXvRCRSBF5VkS2iEgRzpdmnIh4mnh/D2Bkg2txOU4N5GiVuP928NrWAShu\npGxd+YZlccs33HfQsVR1o6puchP4cuAh4MIfELsJIJYUTEvZBvy+wV+5kar6uoj0wGn/vgVIUNU4\nYAXg3RTkq+l8dwLxIhLptS31MO9pGMudQG9gpKp2AE5yt0sT5bcBXzW4FtGq+rPGPkxEnmkw0sf7\nsRLA7RfYCQzyeusgYGUT57CykbK7VXWPu6+niMQ02N/UsZSDf1amFbOkYHwhRETCvR7BOF/6N4nI\nSHFEicjZ7hdPFM4XSz6AiFyDU1PwOVXdAmTjdF6Hisgo4NwjPEwMTj/CfhGJBx5osH83zuieOh8D\nvUTkShEJcR/DRaRPEzHe1GCkj/fDu53/FeA+t+M7C7gBmNJEzK8A14lIXxGJA+6rK6uq64AlwAPu\nz+98YCBOExciMlFEOrvPs4D/B3zYjOtkWgFLCsYXpuF8SdY9HlTVbJwvqSeAfUAO7mgXVV0FPALM\nwfkCHQDMbsF4LwdGAXuA3wFv4vR3NNc/gAigAJgLfNZg/2PAhe7IpH+6/Q5n4HQw78Bp2vozEMYP\n8wBOh/0W4Cvgr6r6GYCIdHdrFt0B3O1/AWYCW933eCezycAwnJ/Vn4ALVTXf3XcasExESnF+1u8B\nf/iBsZsAIbbIjjEHE5E3gTWq2vAvfmPaPKspmHbPbbrJEJEgcW72mgR84O+4jPEHG1tsjDPq5z2c\n+xRygZ+5w0SNaXes+cgYY0w9az4yxhhTr9U1HyUmJmpaWpq/wzDGmFZl4cKFBaqadLhyrS4ppKWl\nkZ2d7e8wjDGmVRGRLc0pZ81Hxhhj6llSMMYYU8+SgjHGmHqWFIwxxtSzpGCMMaaeJQVjjDH1LCkY\nY4yp126SQvbmvfz5szXYtB7GGNO0dpMUlm8v5OlZGygoqfR3KMYYE7DaTVJIS4wCYPOeUj9HYowx\ngavdJIX0BCcpbCqwpGCMMU1pN0khpWMEwUHCZksKxhjTpHaTFII9QaTGR1rzkTHGHEK7SQoAaQmR\nbCoo83cYxhgTsNpXUkiMYsueUhuWaowxTWhXSSE9MYqyyhryiiv8HYoxxgSkdpUU0mwEkjHGHFK7\nSgrpdfcqWFIwxphGtauk0DUuglBPEJtsBJIxxjTKZ0lBRF4UkTwRWdHEfhGRf4pIjogsE5Ehvoql\njidI6J4QaTUFY4xpgi9rClOACYfYPxHIdB83Ak/7MJZ6aQlRbLZhqcYY0yifJQVV/RrYe4gik4BX\n1DEXiBORLr6Kp056onMDW23twcNSVZUV2wttuKoxpl3zZ59CN2Cb1+tcd9v3iMiNIpItItn5+fk/\n6EMHpsRRUV3LPe8tp7qmtn77i7M3c87j3/LElzkHlVdVZqzeTUV1Tf22r9flU1JR/YPiMMaYQNQq\nOppV9TlVHaaqw5KSkn7Qsc4Z2IVbTz2ON7O3cdN/FnGgsoZ9pZU89sU6wkOCeOTzdXyxand9+U+W\n7+S6l7OZMnszACt3FHLVi/N57It1PygOY4wJRP5MCtuBVK/XKe42nxIR7jijNw9P6seMNbu54oV5\n/H7aakoqqnnrp6MY0C2WX7y5hLW7iqmuqeXR/zpf/m8u2Iaq8uYCp3Lz9sJcyqtqDvVRxhjT6vgz\nKUwFrnJHIZ0AFKrqzpb68CtHpfHkZUNYnlvIOwtzuXREdwamxPHslUOJDPVw9UvzeWrWBjYWlDKh\nXzIbC0r5NqeADxZvp2dSFPvLqpi2/OBwyyqrv9dXYYwxrYkvh6S+DswBeotIrohcJyI3ichNbpFp\nwEYgB3geuNlXsTTlrAFdmHLtcCb2T+aO03sBzr0ML10znOLyah79fB2DUuN45OJBRIcF88u3l1JU\nXs3vJvWnZ1IU/5m7pf5YhWVVnPzXWUx6cjYb80ta+lSMMeaY8OXoo0tVtYuqhqhqiqq+oKrPqOoz\n7n5V1f9T1QxVHaCq2b6K5VBGZyTy9BVDSYgOq9/Wr2ssz145lG5xEdx7Vh+iwoI5d1BXdhdV0CMh\nkhN6JnD5yB4s2rqflTsKAXj6qw0UlFSwZU8pZ//zW2as3t3URxpjTMBqFR3N/nDicYnMvvtURqTH\nAzB5uNP9cfGwVIKChAuHpBAdFsytry9mWe5+Xpq9ifOP78b020+ie3wk/++DFQeNWDLGmNbAkkIz\nDUqN452bRnHD2J4AxEaG8OLVw9lZWM75T32HKtx+ei+6xEZw79l92FFYzlvZuX6O2hhjjowlhSMw\nLC2e0OD/XbIR6fFMuWYEESEerh+bTmp8JABjMxMZ2qMjT83MsdqCMaZVsaTwA41Ij2fBveO568ze\n9dtEhNvH92JnYXn9EFZjjGkNLCkcAxGhHkTkoG0nHpfAkO5xvPjtJhumaoxpNSwp+IiI8JPRaWze\nU8a3OQX+DscYY5rFkoIPTeifTGJ0KP+eu4WaWuWBD1dw6+uLWbptv79DM8aYRgX7O4C2LCzYwyXD\nU3l61gb+79VFfLZyF5GhHqYu3cHk4an86YKB/g7RGGMOYjUFH7tsZA8APlu5i9tOy2T+veO5alQP\n3liwjdnWrGSMCTCWFHysW1wEt4/vxT0Ts/jF+Eyiw4L5zVl96B4fyW8/WnnQ9N3GGONvlhRawM9P\ny+SnJ2fUj1AKD/Fw79l9WLe7hCnfbfZvcMYY48WSgp+c0bczJ/dK4nefrObOt5ayt7TS3yEZY4wl\nBX8REZ65Yig3j8vgwyXbufKFef4OyRhjLCn4U0Soh19NyOLes/uwckcRG2zKbWOMn1lSCABn9EsG\nsOm2jTF+Z0khAHSLi6Bvlw58sSrP36EYY9o5SwoBYnzfzmRv2cve0kr++Olqxj/6FZsLSv0dljGm\nnbGkECBO79OZWoVfvr2UZ7/ayKaCUi56dg7rdhf7OzRjTDtiSSFA9O/WgeQO4Xy5Jo8Tesbz8c/H\nIMClz81lV2G5v8MzxrQTlhQChIgwaXBXUuMjeOKyIfTp0oHXbhjJgaoafvHmYmps+m1jTAuwpBBA\n7p6Qxcw7x5EYHQbAcZ1ieGhSf+Zu3MuTM3P8HJ0xpj2wpBBARIRgz8E/kguGdOP8wd34xxfrmL9p\nr58iM8a0F5YUApyI8PCP+tM9PpLb3ljMvqOcDuPrdfm2XrQx5rAsKbQC0WHBPHHZEApKKrjrnWWo\nOv0L5VU1fLZiZ/3rpmzIL+GqF+fz4eIdLRGuMaYVs6TQSvTvFstdZ/bmi9W7mbNhDwBPzszhpv8s\nYvFhVnLLyXOmz1ifZ8NbjTGHZkmhFblqVBqJ0WE88/VGSiqqedmddrsuSTSl7ia4jfl2M5wx5tAs\nKbQi4SEerjkxja/X5XP/hysoKq+mY2QI32049Apum+qSgt0hbYw5DEsKrcwVI3sQFerhvUXbGZ2R\nwPmDU8jevI+K6hpUlWW5+9lVWH5QP0NdUti6t4wqW+nNGHMIPk0KIjJBRNaKSI6I3N3I/u4iMlNE\nFovIMhE5y5fxtAWxkSFcOqI7ADednMGojAQqqmtZvHU/7y3aznlPzOaEP85g2O++YL07RcamglIi\nQjzU1Cpb95b5M3xjTIDzWVIQEQ/wJDAR6AtcKiJ9GxS7D3hLVQcDk4GnfBVPW3L76b149sqhjM1M\nZER6PEECs9bm88h/19KvawfuP6cve0or+WJ1HqUV1eQVV3DicYkAbLJ+BWPMIfiypjACyFHVjapa\nCbwBTGpQRoEO7vNYwMZMNkNUWDBn9ktGRIiNCKF/t1he+HYjOwrLufesPlw7Jp2MpCgWbN5b33R0\nalYnADYW2EI+xpim+TIpdAO2eb3Odbd5exC4QkRygWnAz30YT5s1KiOBqhplbGYio90awYj0eBZs\n3lvfuXx8ahzxUaH1ScIYYxrj747mS4EpqpoCnAX8W0S+F5OI3Cgi2SKSnZ+f3+JBBroz+yUTExbM\n3ROz6reNSI+nuLya6St2AZCWGEnPxCg2WPORMeYQfJkUtgOpXq9T3G3ergPeAlDVOUA4kNjwQKr6\nnKoOU9VhSUlJPgq39RrSvSPLHjyDfl1j67cNT4sH4L+rdpHcIZzI0GB6JkVZTcEYc0i+TAoLgEwR\nSReRUJyO5KkNymwFTgMQkT44ScGqAkdBRA56ndIxkm5xEVTVKOmJUQCkJ0aTX1xBcXmVP0I0xrQC\nPksKqloN3AJMB1bjjDJaKSIPich5brE7gRtEZCnwOnC1Hm4iH9Nsw9M6ApDmJoWeSc6/dbUFVeXp\nWRtYu8umvzDGOIJ9eXBVnYbTgey97X6v56uAE30ZQ3s2Ij2BD5bsID0xEoCebnLIySthYEocGwtK\n+fNna1i9s4h/XjrYn6EaYwKEvzuajQ+NzUwkKtTD0B5O/0J6YhRxkSF8s96ZFmPWWqelbubaPLvT\n2RgDWFJo01LjI1nx2zMZ2sNpRgr2BDG+T2e+WL2byupaZq3NIzhIKC6vtgV8jDGAJYU2r2EH9MT+\nyRSXVzNj9W7mbdzLJcNTCQsO4vNVu/0UoTEmkFhSaGfGZCYSHRbM76etprKmlon9uzA2M5HPV+0+\n7GI9xpi2z5JCOxMW7OHUrE7k7jtAZKiH4ekdOb1vZ7bvP8DqnTYKyZj2zpJCOzSxfzIAozMS3STR\nGRH4aJlNPWVMe2dJoR06uXcSvTvHcOHQFACSYsI4a0AXpszezO6icgBKKqpZs6uIhVv2UWQ3uxnT\nbvj0PgUTmCJDg5l++0kHbfv1mVn8d+Uu/v75OiaP6M61Uxawt7QSgAn9knnmyqH+CNUY08IsKRgA\nuidEctWoNF6avYkPl+wgMSaUB88bzLRlO/lqXT7lVTWEh3j8HaYxxses+cjU+/mpxxEXGUp6YhTv\n/mw05w3qyiXDUzlQVcO8I7yPYeWOQl78dpOPIjXG+IrVFEy9uMhQZtxxMlFhwYQGO38vjMpIIDwk\niJlr8ji5V/NnqJ0yezNvL8xlXO8keiZF+ypkY8wxZjUFc5COUaH1CQEgPMTD6IxEvlyTd0T3Maxx\nJ9n7cImNaDKmNbGkYA7rlN5JbN1bVr+K2+HU1Crrdtclhe12U5wxrYglBXNY43o76ztPW7aT2trD\nf8Fv3lNKRXUtI9Li2bynjGW5hb4O0RhzjFhSMIeVGh9JVnIMj3y+jn4PTOdHT87mnveW8V1OQaPl\n17h3Rv/i9ExCPUF8sKThgnvGmEBlScE0y4tXD+cvFw5k8ohUIkI8fLR0J3e/t7zRsmt2FeEJEoZ0\n78gpWUl8tHQnNc2oYRhj/M9GH5lm6RoXwcXD/rfk9rNfbeCPn65hT0kFCdFhB5VdvbOYnolRhId4\nOGtAF6av3M3S3P0M6d6xpcM2xhwhqymYozLY/YJfsm3/9/at2VVE7+QYAE7ulUSQwMw1eS0anzHm\n6FhSMEdlQLdYPEHC4q0HJ4Xi8ipy9x2gT5cOgHPvw9AeHfnSkoIxrYIlBXNUIkI99OkSw+Jt+wDI\nKypn0dZ99UNRs9yaAsApWZ1YuaOofrI9Y0zgsqRgjtrg1I4s3VZITa1y86uL+PFT33Hr60sAyHJr\nCgCnZjlDWmettdqCMYHOkoI5aoO7x1FSUc1r87aQvWUf4/t0ouhAFYnRYXSNDa8v17tzDF1jw60J\nyZhWwEYfmaN2fGocAL+ftprE6DCeuGwIByprKK2sPmhtaBHhlKxOvJ2dy3VTFjCkR0d+dnIGQUHS\n1KGNMX5iScEctfTEKGIjQig8UMUvxqcTHuIhPMRDx6jQ75W9dkw6hQeqWLmjiBlr8hiRHs/wtHg/\nRG2MORRrPjJHTUQY1qMjsREhXHFCj0OWzUiK5onLhvDRz8cQGhzEJ8t2tlCUxpgjYUnB/CAP/ag/\nb/70BKLDmlfpjA4LZlyvJD5d0bx5lIwxLcuSgvlBusVFkJXc4fAFvZw9sAu7iypYuHWfj6Iyxhwt\nSwqmxZ3Wp7M1IRkToCwpmBYXHRbMKb2TmLbcmpCMCTQ+TQoiMkFE1opIjojc3USZi0VklYisFJHX\nfBmPCRyn900mr7iC9Xkl/g7FGOPFZ0NSRcQDPAmcDuQCC0Rkqqqu8iqTCdwDnKiq+0Skk6/iMYGl\nd2dnGoxNBSX1k+cZY/zPlzWFEUCOqm5U1UrgDWBSgzI3AE+q6j4AVbVbXtuJtMRIADYVlPk5EmOM\nN18mhW7ANq/Xue42b72AXiIyW0TmisiExg4kIjeKSLaIZOfn5/soXNOSYsJDSIwOY1OBNR8ZE0j8\n3dEcDGQC44BLgedFJK5hIVV9TlWHqeqwpKSkFg7R+ErPxCg2FZT6OwxjjJdmJQURuag52xrYDqR6\nvU5xt3nLBaaqapWqbgLW4SQJ0w6kJUZa85ExAaa5NYV7mrnN2wIgU0TSRSQUmAxMbVDmA5xaAiKS\niNOctLGZMZlWLj0xmoKSCorKqwDI3WcJwhh/O+ToIxGZCJwFdBORf3rt6gBUH+q9qlotIrcA0wEP\n8KKqrhSRh4BsVZ3q7jtDRFYBNcBdqrrn6E/HtCbpiVEAbC4oZW9pJVe/tID3bx5dv9SnMablHW5I\n6g4gGzgPWOi1vRi4/XAHV9VpwLQG2+73eq7AHe7DtDN1SWFTQSmzcwoAmLU2n8HdO7K/rJK73lnG\nA+f2JaVjpD/DNKZdOWTzkaouVdWXgeNU9WX3+VScoaY2cY35QXokRCICG/JKmLHaGY383QYnOXy8\nbCefr9rNf1fu9meIxrQ7ze1T+FxEOohIPLAIZ5TQ330Yl2kHwkM8dI2N4MOlO9hTWkl6YhSLt+6n\ntKKa6St3AbBie6GfozSmfWluUohV1SLgx8ArqjoSOM13YZn2Ij0xii17yggOEu46szfVtcoXq3cz\nZ4PTtbTckoIxLaq5SSFYRLoAFwMf+zAe087U9Suc0DOBU3p3ItQTxF8+W0t1rXJK7yQ25JdQVnnI\nMQ3GmGOouUnhIZyRQhtUdYGI9ATW+y4s017UJYXxfToREephSI84tu8/QJfYcC4b2YNahVU7ithX\nWsnpj35V3+dgjPGNZiUFVX1bVQeq6s/c1xtV9QLfhmbag9HHJZDZKZqJA7oAcGJGIgBn9ktmYEos\nAMtyC3l/8XbW55UwbbmtwWCMLzX3juYUEXlfRPLcx7sikuLr4Ezbl5Xcgc/vOJnOHcIBOL2fswDP\njwZ3o3OHcJJiwlixvZC3sp1ptBZsskFvxvhSc5uPXsIZitrVfXzkbjPmmMpK7sCq357J8anOFFgD\nu8Xy+ardrNlVTFpCJGt3F7OvtNLPURrTdjU3KSSp6kuqWu0+pgA2M53xiWDP//5b9u8WS3FFNaHB\nQdx3dl8AFmze66/QjGnzmpsU9ojIFSLicR9XADYdhfG5Ad2cfoUz+yUzJjOR0OAg5m+ypGCMrzQ3\nKVyLMxx1F7ATuBC42kcxGVNveFo8g1JiuX5MOuEhHo5PjWO+1RSM8ZkjGZL6E1VNUtVOOEnit74L\nyxhHbGQIH94yhkFuH8PI9HhW7iiipMLuXTDGF5qbFAZ6z3WkqnuBwb4JyZimjUiPp6ZWWbTFRiEZ\n4wvNTQpBIlI/n7E7B9LhZlg15pgb0r0jocFBzFxry3kb4wvNTQqPAHNE5GEReRj4DviL78IypnFR\nYcGM65XEJ8t2UlOr/g7HmDanuXc0v4IzGd5u9/FjVf23LwMzpinnDupKXnFF/dDUact3smP/AT9H\nZUzb0OwmIFVdBazyYSzGNMtpfToREeLho6U72Fdayc2vLmJ0RgKv3XCCv0MzptVrbvORMQEjMjSY\n8X0788nynfzm/eVEhnr4bsMe5m20W2eM+aEsKZhW6ZyBXdhfVkVpZQ1v3jiKpJgwHpthE/ca80NZ\nUjCt0sm9kshKjuH+c/oyICWWm07OsNqCMceAJQXTKoWHePjsFydxxQk9ALh8ZHc6RobwxoJtfo7M\nmNbNkoJpE8JDPJzUK4lv1hdQa0NVjTlqlhRMmzE2M4mCkgrW7CoGYPv+A+wvs2m2jTkSlhRMmzE2\n01m17Zv1+RyorGHSE99y1zvL/ByVMa2LTVVh2ozOHcLp3TmGb9YXEB7ioaCkkq/W5lNcXkVMeIi/\nwzOmVbCagmlTxmYmMn/zXp79agOdYsKorKnlyzU2T5IxzWVJwbQpY3slUVldy47Ccv5w/gA6xYTx\n6fJd/g7LmFbDkoJpU0akxRMaHETvzjGc1qcTZ/ZLZta6PMoqbf0FY5rDp0lBRCaIyFoRyRGRuw9R\n7gIRUREZ5st4TNsXEerhsUuO55GLByEiTByQTHlVLbPW5vs7NGNaBZ8lBRHxAE8CE4G+wKUi0reR\ncjHAbcA8X8Vi2peJA7rQ313beURaPPFRoUxdssPPURnTOviypjACyFHVjapaCbwBTGqk3MPAn4Fy\nH8Zi2qlgTxAXD0tl+qpdbMwv8Xc4xgQ8XyaFboD3nAO57rZ6IjIESFXVT3wYh2nnrhuTTqgniGe/\n2ujvUIwJeH7raBaRIOBR4M5mlL1RRLJFJDs/39qGzZFJignjkuGpvLc4l52FthiPMYfiy6SwHUj1\nep3ibqsTA/QHZonIZuAEYGpjnc2q+pyqDlPVYUlJST4M2bRVN4ztSa3CH6atobyqptEymwtK+XZ9\nQQtHZkxg8WVSWABkiki6iIQCk4GpdTtVtVBVE1U1TVXTgLnAeaqa7cOYTDuVGh/JzeMy+GjpDs55\n/Fvmb9r7vTL3T13J9a8soKK68aRhTHvgs6SgqtXALcB0YDXwlqquFJGHROQ8X32uMU2584zeTLlm\nOGUV1Vz87Bwue34uS7ftB2BvaSWzcwoor6plWW6hnyM1xn982qegqtNUtZeqZqjq791t96vq1EbK\njrNagvG1cb078cWdJ3Pf2X1Yt7uEn7w0n6LyKj5dsZMad8rtORtsoR7TftkdzabdiQwN5vqxPZly\nzXD2l1Xx/Ncb+XjpTnomRZGVHMNcW73NtGM2S6ppt/p3i+XsAV341zebKK+u4dZTMykqr+K1eVup\nqK4hLNjj7xCNaXFWUzDt2h1n9KKyphZVOHdQF0b1TKCiupal26xfwbRPVlMw7VpGUjTXjE5j7e5i\njusUQ2J0GCJOv8KI9Hh/h2dMi7OkYNq9+87535RccZGh9EnuwNyNe7iNTD9GZYx/WPORMQ2MzUxk\nwea9NleSaZcsKRjTwPVjexIR4uHhj1f9oOOUVlTzr282sr+s8hhFZozvWVIwpoGkmDBuG5/JzLX5\nzFi9+6iOUVpRzTUvLeB3n6zmz5+tPcYRGuM7lhSMacRPRqdxXKdo7v9wJet3F1NdU8tDH63ilL/N\noqi8qtH3rNheyPhHv+KKf83jomfmsHDrPoZ0j+Ot7G1sKiht4TMw5uhYUjCmESGeIP520SDKq2o4\n74nZXPD0d7w4exObCkr5Zt33J807UFnDbW8sZl9pJUXlVewrq+SxycfzzJVDCfUE8ejn6/xwFsYc\nOUsKxjTh+NQ4Pr1tLIO7x7F6VzF/uXAgcZEhzFjz/SalP366mg35pTw2eTBTbxnDnHtO45yBXekU\nE861Y9L4aOkOVu0o8sNZGHNkbEiqMYfQqUM4r14/kuKKajqEh/BdTgGz1uZTU6t4ggSARVv38cqc\nLVw3Jp0xmYnfO8b1Y3ry5MwNzFi9m75dO7T0KRhzRKymYMxhiAgdwkMAOLVPZ/aWVrLEnV0V4IPF\n2wkPCeKO03s1+v6OUaH0TIpiqc2+aloBSwrGHIGTM5PwBAlfuk1ItbXKZyt2Ma5XJ6LCmq54D0qJ\nY1nu/ib3GxMoLCkYcwRiI0P7SX5xAAAWo0lEQVQY1qMjM1bnAU7TUV5xBRMHJB/yfQNTYskrrmBX\nYXlLhGnMUbOkYMwRGt+nM2t2FfPN+nw+XbGLUE8Qp2Z1OuR7BqbEAbDUagsmwFlSMOYIXTqyO1nJ\nMdz86iI+XLKDsZmJxLh9Dk3p17UDwUFSv9KbMYHKkoIxRyg6LJgXrh5OWLCHgpIKJg7octj3hId4\n6J0cY0t9moBnScGYo9AtLoKXrh7OBUNSmND/0P0JdQa6nc2q6uPojDl6lhSMOUoDUmJ55OJBRB9i\n1JG3QSmxFJVXs3lPmY8jM+boWVIwpoXUdTa/nb2tvraws/AAVTW1/gzLmIPYHc3GtJCs5Bgm9Evm\nqVkbWLmjiAOVNczfvJc7Tu/FrafZgj4mMFhNwZgWEhQkPH3FEB44ty9zNuxhV1E53eIijnp6bmN8\nwWoKxrQgEeGaE9O5bGR3QoKCePzLHP4xYx37SivpGBXq7/CMsZqCMf4QFuwhKEgY2ysRVZi94fvT\ncRvjD5YUjPGjgd1i6RAe3OgaDcb4gyUFY/wo2BPEiccl8s36fLt/wQQESwrG+NnYzCR2FJazId+W\n7DT+Z0nBGD8b6y7M82UjK7rVKSipYH9ZZUuFZNoxnyYFEZkgImtFJEdE7m5k/x0iskpElonIDBHp\n4ct4jAlEqfGRjEiL5/Evc8jd9/27nQsPVHHu49/ys/8sOuJjL922n9+8v5yyyupjEappB3yWFETE\nAzwJTAT6ApeKSN8GxRYDw1R1IPAO8BdfxWNMIPvbRYOorVXufGspNbUH9y08OHUlOwvLmbtpD3lF\nR7Yew7Nfb+C1eVu5/c0l1NZan4U5PF/WFEYAOaq6UVUrgTeASd4FVHWmqtb9aTQXSPFhPMYErO4J\nkTx4Xj/mbdrL6D/NYMjDn3P+U7O574PlvL94O+cN6ooqfLZyV7OPWVVTyzfrC+gWF8H0lbv58/Q1\nPjwD01b4Mil0A7Z5vc51tzXlOuDTxnaIyI0iki0i2fn5+ccwRGMCx4VDU/jNWVmcmJHImf2Sqaqp\n5T9ztzLQnXjvuE7RfLJsZ7OPt2jLPorLq7nv7D5cOiKVZ7/ayI79B3x4BqYtCIg7mkXkCmAYcHJj\n+1X1OeA5gGHDhlkd2LRJIsKNJ2UctG1XYTnR4cGEeII4a0AXHv9yPfnFFSTFhB32eDPX5hMcJJyY\nmUiPhChen7+NORv2cMFQq5CbpvmyprAdSPV6neJuO4iIjAfuBc5T1QofxmNMq5McG14/NffZA7oc\ntglpV2E5s3OcG+Fmrc1jWFpHOoSHkJUcQ8fIEL7bsKdF4jatly9rCguATBFJx0kGk4HLvAuIyGDg\nWWCCqub5MBZjWr1enaPJSIriL5+uYem2/ZyW1YlBqXF0iQ1HRKiqqeXaKQtYtbOIy0Z2Z82uYu6Z\nmAU4k/Gd0DOBuRv3oKqIiJ/PxgQqnyUFVa0WkVuA6YAHeFFVV4rIQ0C2qk4F/gpEA2+7/0m3qup5\nvorJmNZMRHjq8qE89/VGpq/cxTsLcwFn8Z5nrhzKB4t3sGpnEaMzEnht3lYATsnqVP/+0RkJfLpi\nF1v3ltEjIcov52ACn0/7FFR1GjCtwbb7vZ6P9+XnG9PW9E6O4ZGLB1FR3Z9VO4pYuGUf//hiPZOe\nmE3hgSrO7NeZZ64YykuzN7NqZxGZnaLr3zsqIwGAORv2WFIwTbI7mo1phcKCPQzu3pHrx/bknZ+N\nIsQTRKgniN+e1x8R4dox6fztokEHNRNlJEWTFBPWaL/CxvwSrn85m4IS69Zr7wJi9JEx5uhlJXfg\n01+MpaS8muTY8CbLiQijMxKYnXNwv0JVTS23vbGE5dsLmb4yictH2sQC7ZnVFIxpAzqEh9A1LuKw\n5U7KTKKgpIKpS3fUb3v8yxyWby8kPCTIpvA2lhSMaU8mHd+V41PjeGDqSvKKy5m6dAdPzszhx0O6\n8aPjuzF7QwHVNbX+DtP4kSUFY9qRYE8Qf7toEGWVNUx6Yja3vr6YQSmxPHheP8ZmJlFcXs3S3P3U\n1irTV+5iyuxNTJm9icKyKn+HblqI9SkY084c1ymaX0/I4nefrOLmcRncfnovQjxBnHhcAiLw9boC\nluUW8tuPVtW/54MlO3jthpFEhtpXRlsnrW21p2HDhml2dra/wzCm1Ss8UEVsRMhB2yY9OZuiA1Xs\nLDzAqJ4JPHrx8czZuIdbXlvEyb2SeO6qYYR4rIGhNRKRhao67HDl7KdrTDvVMCEAnJSZyKaCUkI8\nQfzxxwPpGBXKWQO68PCP+jNzbT7Pfb3RD5GalmRJwRhTb3yfzojAb8/rd9Dw1stH9uC0rE48+9UG\nCg9Y/0JbZknBGFNvUGocC+87nR8P+f5Mqnec0Yui8mqeb1BbyN1XRmW1jVhqKywpGGMOEh8V2uj2\nfl1jOXtgF16cvYm8YmcFuI+X7WDcX2dx47+zbWW3NsKSgjGm2e44vReV1bWc/ujX/PLtpdz6+mI6\ndwhn1tp8nvvG+hvaAksKxphmy0iK5v2bT2RkejzvLMzlxOMS+fyOkzhrQDJ/nb6W7M1768su2LyX\njfklfozWHA0bkmqMOSq7CstJjA4l2BNEUXkV5z7+LUUHqnj3Z6NZt7uYm19dRHKHcKbffhIx4d8f\n6dSUFdsL+ccX69mx/wDR4cG8fM0IIkI9PjyT9sGGpBpjfCo5Npxg956FDuEhvHzNCIJEuOz5edz6\n+hKO6xTNzqJy/vzZmmYfU1X5zfvLWbB5LwnRoczftJcnZ+b46hRMIywpGGOOibTEKF66ZjhF5VX0\nTIri7Z+O5toT0/nP3K3c894yTn1kFje8kv29kUrzNu7hg8XOSr2Ltu5jWW4hvzyjF/++biQ/HtyN\nZ7/eQE6eNUO1FEsKxphjZmBKHF/eOY73bh5NbGQIvzyjN2kJkbydnUt8ZCifr9rNXe8srR+p9OWa\n3Vz5wnx+8eYSPl2+kxdnbyYmPLh+SOw9Z/UhIsTDfR8sp8om6msRNpGJMeaY8r7pLSLUw0c/H4Pi\nNDE9OTOHv05fS15RBWmJUby7MJfeyTF4goRfvr2U8uparj0xjagw56spKSaM+87uy6/eXca1Uxbw\n1OVDjqh/whw5SwrGGJ/y/hK/eVwG1TXK1KXbWbmjkONT43juqqGUVdZwzuPfcqCqhqtGpR30/ouH\npwLwm/eXc+HTc/jjBQMY0r1jS55Ck5bl7qeyupZhafH+DuWYsdFHxpiAsHpnEZsKSjlrQJdG93+z\nPp8731pKXnEF5w/uxq8nZB1ypTlfyi+u4I+frua9RduJCPHwza9PITE6zC+xNFdzRx9ZUjDGtBql\nFdU8NSuH57/ZhEeEK07oTq1CQUkFcREhJMWE0SkmnK5xEYzKSMATJIc/6BGqqVV+9ORs1uwqYvLw\n7rw6bwvXjUnn3rP7HvPPOpaamxSs+cgY02pEhQVz15lZXDKsO3+Ytprnv9lERIiHxJhQ9pdVUVxe\nXV92fJ/OPDb5+Pr+iWPl7extLN9eyGOTj2fS8d0oq6zhlTlbuGFsTzp18E/N5ViymoIxptUqq6wm\nIsSDiFMjKK+qIb+4gukrd/GHaavJSu7ArydmMTojgeAgobyqttEb4fKKypm1Np9vcwqoqK6hY2Qo\ne0or2ZBXQv9usTw0qR9xkaEUHqji1L/NomdSFG/9dBQiwpY9pZz6yFdcPrI7D03q39KXoNmspmCM\nafMargQXHuIhNT6S68f2JKNTNLe/uYSfvDifmLBgalQpq6xhUEosV41Ko2/XDtSq8p+5W3ln4Taq\napSkmDA6RoawqGw/HcKD6ZkUxacrdjJ/014mDe5K9uZ97C2r5OVzR9Qnoh4JUUwensorc7ZQWV3L\nA+f2a9V3YFtNwRjTZlVU1/D1ugJmrs0jPNhDdHgwnyzbwYb80voyoZ4gLhmeymUju5OVHFP/ZV9n\neW4ht725mK17yuieEMmlw7tzw0k9DypTXVPL379Yx1OzNpCeGMWffjyQEemBNSLJOpqNMaYRqsqi\nrfvJLy6norqW4WnxdI2LOOx7amq1flqPpszOKeDX7y4jd98Bzujbma5xEUSFeYgOCyEqzEOoJ4iI\nUA8pHSPpGhdOkAjBQUJ8VOj3ktGxZknBGGP8oKyymse+WM/Hy3ZSXF5FaWUNNYdZayIxOozjU2MZ\nmBLHwJRYBqXE0TEqlLyicpZs2098VCjpiVE/KHlYUjDGmACgqpRX1VJaWU1ldS2lFdXk7jvAzkJn\noaIDVTWs3FHIstxCNuSXUPeVnBgdSkFJ5UHHevDcvlx9YvpRxREQHc0iMgF4DPAA/1LVPzXYHwa8\nAgwF9gCXqOpmX8ZkjDEtSUSICPUc1Pmc2Tmm0bLF5VUs3+4kiPW7S+jVOZphaR0pOlDNxoJSRvZM\n8Hm8PksKIuIBngROB3KBBSIyVVVXeRW7DtinqseJyGTgz8AlvorJGGMCWUx4CKMzEhmdkfi9fae0\nUAy+nCV1BJCjqhtVtRJ4A5jUoMwk4GX3+TvAaeLr3hZjjDFN8mVS6AZs83qd625rtIyqVgOFgO/r\nR8YYYxrVKtZTEJEbRSRbRLLz8/P9HY4xxrRZvkwK24FUr9cp7rZGy4hIMBCL0+F8EFV9TlWHqeqw\npKQkH4VrjDHGl0lhAZApIukiEgpMBqY2KDMV+In7/ELgS21tY2SNMaYN8dnoI1WtFpFbgOk4Q1Jf\nVNWVIvIQkK2qU4EXgH+LSA6wFydxGGOM8ROf3qegqtOAaQ223e/1vBy4yJcxGGOMab5W0dFsjDGm\nZbS6aS5EJB/YcpRvTwQKjmE4vmAxHhsW47ER6DEGenwQODH2UNXDjtRpdUnhhxCR7ObM/eFPFuOx\nYTEeG4EeY6DHB60jRm/WfGSMMaaeJQVjjDH12ltSeM7fATSDxXhsWIzHRqDHGOjxQeuIsV676lMw\nxhhzaO2tpmCMMeYQLCkYY4yp126SgohMEJG1IpIjInf7Ox4AEUkVkZkiskpEVorIbe72eBH5XETW\nu/929HOcHhFZLCIfu6/TRWSeey3fdOe28md8cSLyjoisEZHVIjIqAK/h7e7PeIWIvC4i4f6+jiLy\noojkicgKr22NXjdx/NONdZmIDPFjjH91f9bLROR9EYnz2nePG+NaETnTXzF67btTRFREEt3XfrmO\nR6JdJAWvVeAmAn2BS0Wkr3+jAqAauFNV+wInAP/nxnU3MENVM4EZ7mt/ug1Y7fX6z8DfVfU4YB/O\nCnr+9BjwmapmAYNwYg2Yaygi3YBbgWGq2h9nLrC6lQb9eR2nABMabGvquk0EMt3HjcDTfozxc6C/\nqg4E1gH3ALi/O5OBfu57nnJ/9/0RIyKSCpwBbPXa7K/r2GztIinQvFXgWpyq7lTVRe7zYpwvs24c\nvCLdy8CP/BMhiEgKcDbwL/e1AKfirJQH/o8vFjgJZ3JFVLVSVfcTQNfQFQxEuFPERwI78fN1VNWv\ncSai9NbUdZsEvKKOuUCciHTxR4yq+l93US6AuTjT8tfF+IaqVqjqJiAH53e/xWN0/R34FeA9mscv\n1/FItJek0JxV4PxKRNKAwcA8oLOq7nR37QI6+yksgH/g/MeudV8nAPu9fin9fS3TgXzgJbeJ618i\nEkUAXUNV3Q78Decvxp04KwwuJLCuY52mrlug/g5dC3zqPg+YGEVkErBdVZc22BUwMTalvSSFgCYi\n0cC7wC9Utch7n7u+hF/GDYvIOUCeqi70x+c3UzAwBHhaVQcDpTRoKvLnNQRw2+Un4SSwrkAUjTQ3\nBBp/X7fDEZF7cZpgX/V3LN5EJBL4DXD/4coGovaSFJqzCpxfiEgITkJ4VVXfczfvrqtSuv/m+Sm8\nE4HzRGQzTpPbqTjt93FuMwj4/1rmArmqOs99/Q5OkgiUawgwHtikqvmqWgW8h3NtA+k61mnqugXU\n75CIXA2cA1zutTBXoMSYgfMHwFL3dycFWCQiyQROjE1qL0mhOavAtTi3ff4FYLWqPuq1y3tFup8A\nH7Z0bACqeo+qpqhqGs41+1JVLwdm4qyU59f4AFR1F7BNRHq7m04DVhEg19C1FThBRCLdn3ldjAFz\nHb00dd2mAle5o2dOAAq9mplalIhMwGnSPE9Vy7x2TQUmi0iYiKTjdObOb+n4VHW5qnZS1TT3dycX\nGOL+Xw2Y69gkVW0XD+AsnJEKG4B7/R2PG9MYnOr5MmCJ+zgLp91+BrAe+AKID4BYxwEfu8974vyy\n5QBvA2F+ju14INu9jh8AHQPtGgK/BdYAK4B/A2H+vo7A6zh9HFU4X1zXNXXdAMEZwbcBWI4zkspf\nMebgtMvX/c4841X+XjfGtcBEf8XYYP9mINGf1/FIHjbNhTHGmHrtpfnIGGNMM1hSMMYYU8+SgjHG\nmHqWFIwxxtSzpGCMMaaeJQUTMETkO/ffNBG57Bgf+zeNfZaviMiPRMQnd7Q2PJdjdMwBIjLlWB/X\ntD42JNUEHBEZB/xSVc85gvcE6//mEWpsf4mqRh+L+JoZz3c4N1cV/MDjfO+8fHUuIvIFcK2qbj1s\nYdNmWU3BBAwRKXGf/gkYKyJLxFmHwOPOob/AnYP+p275cSLyjYhMxblDGBH5QEQWirN2wY3utj/h\nzFC6RERe9f4s987Sv4qzzsFyEbnE69iz5H/rNLzq3o2MiPxJnDUwlonI3xo5j15ARV1CEJEpIvKM\niGSLyDp3Tqm6dSqadV5ex27sXK4QkfnutmfFnS5aREpE5PcislRE5opIZ3f7Re75LhWRr70O/xHO\nneumPfP33XP2sEfdAyhx/x2He/e0+/pG4D73eRjO3cvpbrlSIN2rbN0duBE4dw8neB+7kc+6AGd+\nfg/OjKBbgS7usQtx5qYJAubg3IGegHO3bF0tO66R87gGeMTr9RTgM/c4mTh3vYYfyXk1Frv7vA/O\nl3mI+/op4Cr3uQLnus//4vVZy4FuDePHmY/pI3//P7CHfx91k3EZE8jOAAaKSN08QbE4X66VwHx1\n5s6vc6uInO8+T3XL7TnEsccAr6tqDc5kcF8Bw4Ei99i5ACKyBEjDmb+/HHhBnJXoPm7kmF1wpvP2\n9paq1gLrRWQjkHWE59WU04ChwAK3IhPB/yaxq/SKbyFwuvt8NjBFRN7CmZyvTh7OLK6mHbOkYFoD\nAX6uqtMP2uj0PZQ2eD0eGKWqZSIyC+cv8qNV4fW8BghW1WoRGYHzZXwhcAvO7LHeDuB8wXtr2Hmn\nNPO8DkOAl1X1nkb2Valq3efW4P6+q+pNIjISZ/GkhSIyVFX34FyrA838XNNGWZ+CCUTFQIzX6+nA\nz8SZZhwR6SXOQjoNxQL73ISQhbPEaZ2quvc38A1widu+n4SziluTM2uKs/ZFrKpOA27HWf6zodXA\ncQ22XSQiQSKSgTMR3tojOK+GvM9lBnChiHRyjxEvIj0O9WYRyVDVeap6P06Npm4q5144TW6mHbOa\ngglEy4AaEVmK0x7/GE7TzSK3szefxpeu/Ay4SURW43zpzvXa9xywTEQWqTP9d533gVHAUpy/3n+l\nqrvcpNKYGOBDEQnH+Sv9jkbKfA08IiLi9Zf6Vpxk0wG4SVXLReRfzTyvhg46FxG5D/iviAThzNT5\nf8CWQ7z/ryKS6cY/wz13gFOAT5rx+aYNsyGpxviAiDyG02n7hTv+/2NVfecwb/MbEQkDvgLG6CGG\n9pq2z5qPjPGNPwCR/g7iCHQH7raEYKymYIwxpp7VFIwxxtSzpGCMMaaeJQVjjDH1LCkYY4ypZ0nB\nGGNMvf8P9XPTq9fuSQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x161401080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "[[[[ 0.41398042 -0.3732289   0.50902146  0.08698988 -0.27155447\n",
      "     0.1033586   0.04008012  0.4137684 ]\n",
      "   [ 0.20727822  0.00956736  0.16597123  0.34360558  0.04769094\n",
      "     0.2560958  -0.29389828  0.16682062]\n",
      "   [ 0.10263124 -0.44819716  0.5135923   0.658251   -0.38794944\n",
      "     0.5680509  -0.65119255 -0.37222615]]\n",
      "\n",
      "  [[ 0.2623747  -0.99366915  0.22317107  0.23255284 -0.15123068\n",
      "    -0.11505987 -0.09448225 -0.29430225]\n",
      "   [ 0.43642783 -0.65524817  0.3925139   0.3149932  -0.3638792\n",
      "     0.00242929 -0.3626171  -0.25522646]\n",
      "   [ 0.2545965  -1.0088835   0.43601584  0.551217   -0.2613807\n",
      "     0.5402875  -0.79990774 -1.0314251 ]]\n",
      "\n",
      "  [[ 0.7259906  -0.7432253  -0.07079029 -0.54793066  0.01771261\n",
      "    -0.06857102  0.2637257  -0.4712634 ]\n",
      "   [ 0.37355065 -0.5199727  -0.0208152  -0.40203062 -0.60505533\n",
      "     0.03866516  0.29742897 -0.5454258 ]\n",
      "   [ 0.566726   -0.98969793  0.04137279 -0.3593763  -0.5223639\n",
      "     0.47665     0.1073807  -0.93892324]]\n",
      "\n",
      "  [[ 0.4166018  -0.5918128   0.02148389  0.32646546 -0.54219955\n",
      "     0.82802     0.41423047 -0.31809562]\n",
      "   [ 0.30908325 -0.93977726 -0.2975404   0.39044207 -1.4340997\n",
      "     1.2039529   0.14383028 -0.34570408]\n",
      "   [ 0.19337876 -1.1594908  -0.4303174   0.88412267 -1.2708875\n",
      "     1.4770103   0.27362782 -0.42280376]]]\n",
      "\n",
      "\n",
      " [[[ 0.15615524  0.37288448  0.17589048 -0.28263813  0.27491695\n",
      "    -0.12474836  0.30238488  0.5029342 ]\n",
      "   [ 0.1390019   0.5751978   0.08400582 -0.2483579  -0.26206183\n",
      "    -0.0466077   0.07191803  0.33889824]\n",
      "   [-0.14011084  0.28216413  0.09485     0.0085798  -0.2938282\n",
      "     0.55257773 -0.14562036 -0.01772025]]\n",
      "\n",
      "  [[ 0.5035832  -0.60925674 -0.10686449  0.7108877   0.41306424\n",
      "    -0.02199422 -0.14336637  0.44947135]\n",
      "   [ 0.17131668 -0.20430653 -0.39055654  0.7305354   0.04220778\n",
      "     0.03715257 -0.4727619   0.43677288]\n",
      "   [ 0.25619566 -0.718933   -0.5126944   1.0044904  -0.44198766\n",
      "     0.41747096 -0.57266223  0.22313999]]\n",
      "\n",
      "  [[ 0.5248569  -0.28746313 -0.15224949 -0.28640366 -0.19869821\n",
      "    -0.1436153  -0.08671457  0.21312901]\n",
      "   [ 0.1864004  -0.3201921  -0.2247514  -0.25977755 -0.70186645\n",
      "     0.13679472 -0.1605518   0.28585383]\n",
      "   [ 0.0053173  -0.61359286 -0.17321041  0.02885597 -0.75319326\n",
      "     0.42003086 -0.2715319  -0.0461846 ]]\n",
      "\n",
      "  [[ 0.26019982 -0.724412   -0.23787187 -0.50014824  0.40184146\n",
      "     0.32983515  0.24333839 -0.18153098]\n",
      "   [ 0.21233602 -0.7748948  -0.6218688  -0.30538222 -0.03423813\n",
      "     0.6445326  -0.01628011 -0.07382615]\n",
      "   [ 0.04273625 -0.91775537 -0.5839455  -0.01804918 -0.2376289\n",
      "     1.2547314   0.1102772  -0.44737807]]]\n",
      "\n",
      "\n",
      " [[[ 0.07553226  0.46829396 -0.30013254 -0.4748572   0.2919199\n",
      "    -0.01233617  0.38350233  0.38183227]\n",
      "   [-0.13709618  0.71527255 -0.7475792  -0.5047582   0.04715826\n",
      "    -0.03460923  0.06438146  0.48142815]\n",
      "   [-0.37940302  0.49000514 -0.65862924 -0.13132924 -0.10551595\n",
      "     0.51365924 -0.13656345 -0.11004293]]\n",
      "\n",
      "  [[ 0.52811915 -0.35675067 -0.27683413 -0.14223789  0.0145232\n",
      "    -0.03528319 -0.05782563  0.0773056 ]\n",
      "   [ 0.00509821  0.1695891  -0.5347744   0.04798573 -0.6176403\n",
      "     0.06144961 -0.42531708  0.32045445]\n",
      "   [-0.18561031 -0.12618223 -0.32261303  0.25073463 -0.79952276\n",
      "     0.63100094 -0.3553567   0.02183939]]\n",
      "\n",
      "  [[ 0.34168497  0.82338184  0.19756359  0.35497898  0.73925036\n",
      "    -0.02777871  0.23260999  0.3462195 ]\n",
      "   [ 0.25437883  0.98534703 -0.01774017  0.25668493  0.5815737\n",
      "     0.48618773  0.01125596  0.47925246]\n",
      "   [ 0.17027406  0.84608984 -0.03445465  0.22162575  0.3217688\n",
      "     0.9218224  -0.15708444  0.14144634]]\n",
      "\n",
      "  [[ 0.1253962  -0.188508    0.26830277 -0.4485957  -0.02251001\n",
      "     0.41524157  0.3656521  -0.0125987 ]\n",
      "   [ 0.19244236  0.23777394  0.25612298 -0.29023656 -0.00798218\n",
      "     0.7055952   0.2812878   0.23886521]\n",
      "   [-0.03843948 -0.01577176  0.1866315  -0.5863657  -0.19782737\n",
      "     0.9250554   0.23490287  0.04353372]]]\n",
      "\n",
      "\n",
      " [[[ 0.195515    0.36621952  0.3839531  -0.46424437  0.06697903\n",
      "     0.0508491   0.2826397   0.14550817]\n",
      "   [ 0.0730127   0.43058726  0.13205324 -0.29670575 -0.38336596\n",
      "     0.03668405  0.03989718  0.14785013]\n",
      "   [-0.42823562  0.35691133  0.444589   -0.2277432  -0.5903893\n",
      "     0.2201066  -0.25146234 -0.07204422]]\n",
      "\n",
      "  [[ 0.1405728   0.03128853  0.01939031 -0.11102453  0.00450257\n",
      "    -0.34672272  0.12435905  0.33232608]\n",
      "   [ 0.26014435  0.12225061  0.06006166 -0.34317863 -0.6989866\n",
      "    -0.2675939  -0.37258157  0.00180751]\n",
      "   [-0.0775718  -0.23691714 -0.02504568 -0.33941892 -0.7717997\n",
      "     0.2587412  -0.5477084  -0.2413158 ]]\n",
      "\n",
      "  [[ 0.6260264   0.11972844  0.35997307  0.04574983  0.24173091\n",
      "    -0.16207096  0.34895408 -0.44521573]\n",
      "   [ 0.46836913  0.44812268  0.5073562  -0.15539527  0.29706338\n",
      "    -0.15544496  0.07978384 -0.47482383]\n",
      "   [ 0.31272537  0.4113924   0.46024013 -0.24315147 -0.14886856\n",
      "     0.20969898 -0.26266488 -0.9073741 ]]\n",
      "\n",
      "  [[ 0.31475922 -0.45208442  0.20662756 -0.52296644  0.5102144\n",
      "     0.18667684  0.5184641  -0.2805478 ]\n",
      "   [ 0.41401026 -0.16989896  0.03784234 -0.60284364  0.3199457\n",
      "     0.32723522  0.229568   -0.3195064 ]\n",
      "   [ 0.21890824 -0.35743073  0.03886801 -0.94006133 -0.09840047\n",
      "     0.9402721   0.06453239 -0.6620061 ]]]]\n",
      "[[[[ 2.62426734e-01 -2.58191913e-01  3.26916814e-01 -3.90427440e-01\n",
      "    -4.69993562e-01  1.09472550e-01 -1.40993103e-01  3.00149441e-01\n",
      "    -1.33795246e-01  3.01788002e-01 -4.29614842e-01  3.48387003e-01\n",
      "     1.45929530e-01  1.75043166e-01 -6.63987128e-03  6.70430530e-03]\n",
      "   [ 7.64025271e-01  8.65994155e-01  7.90580332e-01 -1.02918103e-01\n",
      "     5.01402915e-01 -4.84970152e-01 -3.78537148e-01 -1.11842310e+00\n",
      "    -8.78185093e-01 -3.97489667e-02  9.64592695e-01  5.03880858e-01\n",
      "    -4.23404485e-01  6.20521270e-02  1.49330676e-01  3.66799049e-02]\n",
      "   [-4.15025502e-01  9.04910207e-01  9.26543847e-02 -3.29812914e-01\n",
      "    -1.18134975e+00 -7.87288010e-01 -3.21554333e-01  3.93923938e-01\n",
      "     1.35992992e+00 -1.26132771e-01  3.72654408e-01  1.30609858e+00\n",
      "     1.01025224e+00  4.16373968e-01 -2.08883762e-01  1.07312754e-01]\n",
      "   [ 4.40134406e-02 -2.05515966e-01 -2.94440776e-01 -9.26511347e-01\n",
      "     3.82231057e-01 -3.45043577e-02  8.27532053e-01 -1.30991590e+00\n",
      "    -9.20514241e-02  2.40429002e-03  8.49310040e-01 -4.55350466e-02\n",
      "    -5.50164236e-03 -2.99310774e-01  2.70243645e-01 -2.88224846e-01]\n",
      "   [ 2.97757298e-01  9.21494305e-01  1.02287745e+00  1.51578021e+00\n",
      "    -8.14030647e-01 -7.16772258e-01  5.16152740e-01 -3.15423548e-01\n",
      "     6.42184198e-01  1.14328623e+00  4.67767477e-01 -8.42960298e-01\n",
      "     3.53980958e-01  1.71539441e-01  5.39187193e-01 -8.52510214e-01]\n",
      "   [ 2.20371500e-01 -2.02017605e-01 -3.58137667e-01 -5.14118791e-01\n",
      "    -6.29365385e-01  4.24859852e-01 -1.28680572e-01  7.66813802e-03\n",
      "     9.53764170e-02 -2.77301162e-01 -6.11561239e-01  3.83596629e-01\n",
      "    -1.05653275e-02  2.38287345e-01  3.96321476e-01  1.04993716e-01]\n",
      "   [-9.31135297e-01  1.56136423e-01  1.56329110e-01 -4.02781457e-01\n",
      "    -3.18651497e-01 -3.73638928e-01 -6.80197716e-01  5.38370479e-03\n",
      "     4.80150074e-01  3.09572965e-01  1.91411734e-01 -2.78196275e-01\n",
      "    -3.40751886e-01 -2.78495163e-01  1.69693261e-01 -9.77424532e-02]\n",
      "   [-1.22191511e-01  1.02519751e+00  5.98799229e-01 -3.48944098e-01\n",
      "    -3.52992296e-01 -1.03102863e+00 -4.46277350e-01 -1.88567519e-01\n",
      "     7.78609037e-01  5.72559610e-02 -1.81197539e-01  4.93420601e-01\n",
      "     2.97757238e-01  7.38854408e-01 -5.02752483e-01  6.01755261e-01]]\n",
      "\n",
      "  [[ 5.60954772e-03  3.17756444e-01 -1.33629575e-01  4.20195729e-01\n",
      "     4.85666871e-01 -6.72525093e-02 -2.26215586e-01  1.81480069e-02\n",
      "     3.21132421e-01 -1.47711471e-01 -2.47338444e-01  2.01960236e-01\n",
      "    -9.90158245e-02 -5.67290843e-01 -5.62893711e-02  1.78876951e-01]\n",
      "   [ 5.69229901e-01  4.82409745e-01 -5.15206933e-01  7.01696575e-01\n",
      "     2.10694641e-01  8.26446533e-01  1.09839346e-02  7.07027197e-01\n",
      "    -3.91544670e-01 -6.14398956e-01  5.01734726e-02 -4.51006114e-01\n",
      "    -2.38869056e-01  2.48372704e-01 -1.50517344e+00  8.99705142e-02]\n",
      "   [-1.01804376e+00  5.45486033e-01 -1.49680546e-03 -2.66288280e-01\n",
      "    -6.99717820e-01  2.30664387e-01  8.77124369e-02 -6.72968999e-02\n",
      "     7.55051849e-04 -2.81015098e-01  3.19101691e-01 -1.35008350e-01\n",
      "    -1.45353496e-01 -5.19908071e-01 -3.95086795e-01  4.42467213e-01]\n",
      "   [ 1.03859194e-01 -5.16910732e-01 -6.94888771e-01 -9.74374563e-02\n",
      "    -8.15373063e-02  3.69056225e-01  1.60306513e-01  4.37894166e-01\n",
      "     2.54887119e-02 -1.59678936e-01  3.11306775e-01 -1.21615626e-01\n",
      "    -3.60648096e-01  5.63041031e-01  2.70899832e-01  3.37864667e-01]\n",
      "   [-1.92914039e-01  1.84192026e+00  2.24668130e-01  1.01305997e+00\n",
      "    -1.93280205e-01  5.10047317e-01  2.09450507e+00 -5.32379746e-01\n",
      "    -3.64301503e-01  1.22924875e-02 -1.98773468e+00 -4.99082565e-01\n",
      "    -2.25949422e-01  1.89512327e-01 -1.84584543e-01  7.56052971e-01]\n",
      "   [-1.09355778e-01  2.63969034e-01 -8.26100349e-01  3.77161622e-01\n",
      "     1.27928052e-02  1.41152844e-01 -6.76801920e-01 -2.11230427e-01\n",
      "     3.98778498e-01 -2.29692057e-01 -7.09397346e-02 -3.83735329e-01\n",
      "     3.30358326e-01 -2.03338474e-01 -2.26679280e-01 -2.40685239e-01]\n",
      "   [ 2.65350997e-01  3.13040942e-01 -2.60998636e-01  2.70977974e-01\n",
      "     1.03599317e-01 -3.71497482e-01 -3.14104825e-01  5.41878283e-01\n",
      "    -5.47709823e-01  6.04577176e-03  8.29861581e-01  4.40193534e-01\n",
      "     2.23540105e-02 -2.98862934e-01 -3.72090526e-02  1.07685849e-01]\n",
      "   [-7.63610363e-01  5.38577139e-01  1.54342696e-01  4.52947646e-01\n",
      "     8.16302001e-01 -6.33510947e-01  4.24577922e-01  8.73969913e-01\n",
      "     1.32177979e-01 -2.06391811e-02 -8.61241519e-01  8.43009531e-01\n",
      "     8.77537787e-01  2.15221252e-02 -1.45194098e-01  2.86852270e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.28276423e-02  8.65080208e-02 -1.46590665e-01 -2.71509886e-01\n",
      "    -5.18899858e-01 -1.71445180e-02  1.48712054e-01 -4.31109011e-01\n",
      "    -7.14186847e-01 -1.50447547e-01 -2.40348671e-02  1.20674120e-02\n",
      "    -5.96207261e-01  3.14349890e-01  2.68009484e-01  1.38627747e-02]\n",
      "   [ 8.14568549e-02  3.32895398e-01  2.32163280e-01  1.99207604e-01\n",
      "    -5.94321787e-01  3.41816723e-01  1.88092077e+00  4.45560694e-01\n",
      "    -7.88341820e-01  1.85459793e-01  4.74968582e-01 -4.00526255e-01\n",
      "    -8.18688452e-01  5.52320063e-01  8.85296643e-01  1.45585269e-01]\n",
      "   [-6.12515323e-02  5.95697880e-01  9.51552466e-02 -1.22998285e+00\n",
      "    -7.60760486e-01  7.92302251e-01  2.17765391e-01  1.92690164e-01\n",
      "     3.88833731e-01  5.08396281e-03  2.94765890e-01  4.05415982e-01\n",
      "     7.55658805e-01  5.79311140e-02 -1.93299562e-01  2.97774583e-01]\n",
      "   [-6.19859576e-01  3.03576022e-01  7.88129032e-01 -2.37354922e+00\n",
      "    -1.48814440e+00 -5.22632182e-01 -1.24141634e-01  5.65305114e-01\n",
      "     5.09441435e-01  2.94190645e-01  2.40232840e-01 -3.86227936e-01\n",
      "     1.55934703e+00  2.47240543e-01  5.78482032e-01  2.54630238e-01]\n",
      "   [-1.36947477e+00 -1.21152878e+00  9.28044081e-01  9.75145340e-01\n",
      "     1.65103042e+00 -2.07419729e+00 -2.87800640e-01  1.72929800e+00\n",
      "     9.69035923e-01  1.37454778e-01 -8.35456848e-01 -4.42273110e-01\n",
      "    -1.92319065e-01 -1.69386852e+00 -7.14878917e-01  1.48248866e-01]\n",
      "   [ 1.71913728e-01 -3.10646623e-01 -2.05422118e-01 -6.40741527e-01\n",
      "    -7.35108912e-01 -7.95532688e-02  2.97026038e-01 -3.30991387e-01\n",
      "     1.10153049e-01 -2.51031309e-01  3.14090669e-01 -6.54690087e-01\n",
      "     1.70650467e-01  5.58656901e-02  8.52666497e-02  1.42887622e-01]\n",
      "   [-5.61386824e-01  4.54370141e-01  1.81446150e-02 -1.59719372e+00\n",
      "    -9.37532425e-01 -5.95695794e-01  2.75398698e-02 -1.96986794e-01\n",
      "    -1.76935390e-01 -1.25198245e-01 -1.51123375e-01  5.69387861e-02\n",
      "     2.57365078e-01 -2.11075202e-01  6.10163033e-01 -3.97424661e-02]\n",
      "   [-1.78914726e-01  1.35010555e-01 -3.01861197e-01 -1.04419184e+00\n",
      "    -1.28766346e+00 -2.62570798e-01 -8.53087977e-02  3.11687589e-01\n",
      "     3.85996178e-02 -3.81425917e-02 -1.37569284e+00 -1.24176085e+00\n",
      "    -1.89286649e-01 -1.41320303e-01  6.49228156e-01 -2.27355599e-01]]\n",
      "\n",
      "  [[-3.12269568e-01 -1.14840172e-01 -6.29027858e-02 -3.38525064e-02\n",
      "    -1.34796157e-01 -3.18728209e-01 -1.34205252e-01  9.30394605e-02\n",
      "    -1.08802460e-01 -2.26716295e-01  1.89158276e-01  2.91247785e-01\n",
      "    -1.58848211e-01 -4.31617647e-02  8.79297778e-02 -2.43222579e-01]\n",
      "   [ 8.36381793e-01  1.05005074e+00  7.66626075e-02  2.35476327e+00\n",
      "    -1.11332022e-01 -1.16372883e+00 -1.15281805e-01 -6.13536179e-01\n",
      "    -4.23698843e-01 -4.21365425e-02  1.21966377e-01 -9.82665271e-02\n",
      "    -9.84832764e-01 -1.38564515e+00 -1.35008645e+00  4.86225963e-01]\n",
      "   [-1.15184702e-01  5.02759933e-01 -2.66014189e-01  7.51864254e-01\n",
      "    -2.38119349e-01  1.57304335e+00  3.84338677e-01  6.16171241e-01\n",
      "    -6.21436298e-01 -3.13037783e-02 -1.54280722e-01  4.43581104e-01\n",
      "    -2.25399300e-01 -2.05889747e-01 -1.51342124e-01  6.27681911e-01]\n",
      "   [ 6.37795925e-01 -8.87373328e-01  1.61523297e-02 -5.02092659e-01\n",
      "    -5.76822042e-01 -5.03028810e-01  2.24612117e-01 -8.33204806e-01\n",
      "     3.87840688e-01 -2.87039876e-01  7.15645075e-01 -1.08895373e+00\n",
      "    -1.56943095e+00 -1.48379624e+00 -4.82125878e-01  2.56086648e-01]\n",
      "   [ 1.23751450e+00 -1.19268763e+00 -3.70647646e-02  3.36413682e-01\n",
      "     2.24594846e-02  4.99726743e-01  4.30303782e-01  1.72402367e-01\n",
      "     4.70867664e-01  2.19360352e-01  4.99726087e-02  1.13383047e-01\n",
      "    -1.44229579e+00 -9.19162184e-02  3.51218671e-01 -4.60783601e-01]\n",
      "   [-2.87045777e-01 -2.18348444e-01 -1.72624469e-01 -2.95581013e-01\n",
      "     7.25390911e-02 -2.95670092e-01  1.43143311e-01  4.83222276e-01\n",
      "    -2.38084584e-01 -5.94659634e-02  2.88010001e-01 -1.85160600e-02\n",
      "    -5.67212403e-01 -1.82069898e-01 -4.62249339e-01  2.50243992e-01]\n",
      "   [-2.00606093e-01  1.02305949e-01  1.90350279e-01  1.22638293e-01\n",
      "     5.80649853e-01  6.88827753e-01  3.91493261e-01  2.49529585e-01\n",
      "     3.32801342e-01  2.64317691e-01  4.66099203e-01  2.15635344e-01\n",
      "    -6.40361428e-01 -4.48592007e-01  4.84375060e-01 -3.26309055e-01]\n",
      "   [ 4.58169192e-01  8.66867900e-01 -2.69212812e-01  4.51043785e-01\n",
      "     5.73916018e-01 -6.35957718e-01  5.18417478e-01 -4.46534008e-01\n",
      "     3.96830887e-02 -1.37372255e-01  5.83354950e-01  4.19075876e-01\n",
      "    -1.82517743e+00 -1.43976462e+00  6.81195080e-01  1.77271262e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_path = 'imgs/ruffy_001.jpeg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#W1 = tf.constant(parameters['W1'], dtype = tf.float32)\n",
    "#W2 = tf.constant(parameters['W2'], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"def net_input(X, parameters):\n",
    "    \n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding='SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1, 4, 4, 1], strides = [1, 4, 4, 1], padding='SAME')\n",
    "    # FLATTEN\n",
    "    P = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P, 3, activation_fn=None)\n",
    "\n",
    "    return Z3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_test, Y_test, parameters):\n",
    "\n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        m = X_test.shape[0]\n",
    "        p = np.zeros((1,m))\n",
    "    \n",
    "        Z3 = forward_propagation(X_test, parameters)\n",
    "        predict_op = tf.argmax(Z3, 1) #Z3Yargmax()\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1)) #True or False\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))#True = 1., False = 0.cast\n",
    "\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Accuracy:\", test_accuracy)\n",
    "    \"\"\"\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    return p\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'filter' of 'Conv2D' Op has type float32 that does not match type float64 of argument 'input'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    528\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_TensorConversionFunction\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2331\u001b[0m           \u001b[0;34m\"Incompatible type conversion requested to type '%s' for variable \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m           \"of type '%s'\" % (dtype.name, v.dtype.name))\n\u001b[0m\u001b[1;32m   2333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible type conversion requested to type 'float64' for variable of type 'float32_ref'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-60d5838b895a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-d80a085cb8cf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(X_test, Y_test, parameters)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mZ3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpredict_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Z3Yargmax()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#True or False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-680817177e31>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# CONV2D: stride of 1, padding 'SAME'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# RELU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1072\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/naohi/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    561\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 563\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'filter' of 'Conv2D' Op has type float32 that does not match type float64 of argument 'input'."
     ]
    }
   ],
   "source": [
    "predict(X_test, Y_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_mislabeled_images(classes, X, y, p):\n",
    "    \"\"\"\n",
    "    Plots images where predictions and truth were different.\n",
    "    X -- dataset\n",
    "    y -- true labels\n",
    "    p -- predictions\n",
    "    \"\"\"\n",
    "    a = p + y\n",
    "    mislabeled_indices = np.asarray(np.where(a == 1))\n",
    "    plt.rcParams['figure.figsize'] = (40.0, 40.0) # set default size of plots\n",
    "    num_images = len(mislabeled_indices[0])\n",
    "    for i in range(num_images):\n",
    "        index = mislabeled_indices[1][i]\n",
    "        \n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(X[:,index].reshape(64,64,3), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Prediction: \" + classes[int(p[0,index])].decode(\"utf-8\") + \" \\n Class: \" + classes[y[0,index]].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
